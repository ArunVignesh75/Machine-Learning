{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "14gappNro_yTu4YsxOxiLZb8PaPkly4je",
      "authorship_tag": "ABX9TyMDIIhCpEqdPXLvke5RQI/U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArunVignesh75/Machine-Learning/blob/main/License_plate_YOLOV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LICENSE PLATE DETECTION & RECOGNITION**"
      ],
      "metadata": {
        "id": "eCqep0nPhkvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONTENTS\n",
        "\n",
        "\n",
        "1.   Importing Packages\n",
        "2.   Data Pre-processing\n",
        "\n",
        "1.   Data Augmentation\n",
        "2.   Spliting the Data\n",
        "\n",
        "\n",
        "5.   YOLOV8 Model Training\n",
        "2.   Evaluating the Model\n",
        "\n",
        "\n",
        "7.   Test Data Predictions\n",
        "2.   Alphanumeric Data Recognition\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mv7yVCbuhxRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV9-awLNaDbc",
        "outputId": "37a66e83-0279-4a7c-f83a-179c74ec3a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.39)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3jdm1MLxGsK",
        "outputId": "0f6b0623-5e64-4009-dae8-a83cebfd96dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.11.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnrIgGlE9Q7a",
        "outputId": "5e18ebbc-97de-433f-88d1-84e870b91cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.10/dist-packages (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.18.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.3)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.4.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.4)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->easyocr) (12.5.40)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-bidi->easyocr) (1.16.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTING NESSCESSARY PACKAGES**"
      ],
      "metadata": {
        "id": "8A4OSfIThcdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import ultralytics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from ultralytics import YOLO\n",
        "from easyocr import Reader\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "7sUrEOVWxnJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PRE-PROCESSING**"
      ],
      "metadata": {
        "id": "tS4RP8GThTOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the training images\n",
        "image_folder = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_train'\n",
        "\n",
        "# Function to get image dimensions\n",
        "def get_image_dimensions(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    return image.shape[:2]  # Return (height, width)\n",
        "\n",
        "# Function to resize image to target dimensions\n",
        "def resize_image(image_path, target_dimensions):\n",
        "    image = cv2.imread(image_path)\n",
        "    resized_image = cv2.resize(image, (target_dimensions[1], target_dimensions[0]))  # Note: cv2.resize uses (width, height)\n",
        "    cv2.imwrite(image_path, resized_image)\n",
        "\n",
        "# Gather dimensions of all images\n",
        "dimensions_counter = Counter()\n",
        "image_paths = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        dimensions = get_image_dimensions(image_path)\n",
        "        dimensions_counter[dimensions] += 1\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "# Determine the most common dimensions\n",
        "most_common_dimensions = dimensions_counter.most_common(1)[0][0]\n",
        "\n",
        "# Resize mismatched images\n",
        "for image_path in tqdm(image_paths, desc=\"Resizing images\"):\n",
        "    current_dimensions = get_image_dimensions(image_path)\n",
        "    if current_dimensions != most_common_dimensions:\n",
        "        resize_image(image_path, most_common_dimensions)\n",
        "\n",
        "print(f\"All images have been resized to the most common dimensions: {most_common_dimensions}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8MA6ITYY65AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths\n",
        "image_folder = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_train'\n",
        "label_folder = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_train_label'\n",
        "\n",
        "# Ensure output directories exist\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "os.makedirs(label_folder, exist_ok=True)\n",
        "\n",
        "# Define the augmentation pipeline\n",
        "augmentation_pipeline = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomRotate90(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.HueSaturationValue(p=0.2)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
        "\n",
        "# Function to read YOLO annotation file\n",
        "def read_yolo_annotation(annotation_path):\n",
        "    with open(annotation_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    for line in lines:\n",
        "        parts = line.strip().split()\n",
        "        class_labels.append(int(parts[0]))\n",
        "        bboxes.append([float(p) for p in parts[1:]])\n",
        "    return bboxes, class_labels\n",
        "\n",
        "# Function to save YOLO annotation file\n",
        "def save_yolo_annotation(annotation_path, bboxes, class_labels):\n",
        "    with open(annotation_path, 'w') as file:\n",
        "        for bbox, class_label in zip(bboxes, class_labels):\n",
        "            file.write(f'{class_label} ' + ' '.join([f'{p:.6f}' for p in bbox]) + '\\n')\n",
        "\n",
        "# Process each image and its corresponding annotation\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg'):  # Assuming the images are in .jpg format\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        label_path = os.path.join(label_folder, os.path.splitext(filename)[0] + '.txt')\n",
        "\n",
        "        # Load image and annotations\n",
        "        image = cv2.imread(image_path)\n",
        "        bboxes, class_labels = read_yolo_annotation(label_path)\n",
        "\n",
        "        # Perform augmentation\n",
        "        augmented = augmentation_pipeline(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "        aug_image = augmented['image']\n",
        "        aug_bboxes = augmented['bboxes']\n",
        "        aug_class_labels = augmented['class_labels']\n",
        "\n",
        "        # Save augmented image with a unique filename\n",
        "        augmented_filename = 'aug_' + filename\n",
        "        output_image_path = os.path.join(image_folder, augmented_filename)\n",
        "        cv2.imwrite(output_image_path, aug_image)\n",
        "\n",
        "        # Save augmented annotation with a unique filename\n",
        "        output_label_path = os.path.join(label_folder, 'aug_' + os.path.splitext(filename)[0] + '.txt')\n",
        "        save_yolo_annotation(output_label_path, aug_bboxes, aug_class_labels)\n",
        "\n",
        "print(\"Data augmentation completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0F4brPlqxJX0",
        "outputId": "e88f63bb-0cf0-42f9-b54a-711336e858b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SPLITING THE DATASET**"
      ],
      "metadata": {
        "id": "kozRFzgLhA0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_img = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_train'\n",
        "train_path_label = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_train_label'\n",
        "val_path_img = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_val_image'\n",
        "val_path_label = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/Licplatesdetection_train/license_plates_detection_val_label'\n",
        "test_path = '/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/test'"
      ],
      "metadata": {
        "id": "EcMe2ksDIBga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure output directories exist\n",
        "os.makedirs(val_path_img, exist_ok=True)\n",
        "os.makedirs(val_path_label, exist_ok=True)\n",
        "\n",
        "# Get list of all image files\n",
        "image_files = [f for f in os.listdir(train_path_img) if f.endswith('.jpg')]\n",
        "label_files = [f.replace('.jpg', '.txt') for f in image_files]\n",
        "\n",
        "# Split into training and validation sets (80:20)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    image_files, label_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Function to move files\n",
        "def move_files(files, source_dir, target_dir):\n",
        "    for file in files:\n",
        "        shutil.move(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
        "\n",
        "# Move validation images and labels\n",
        "move_files(val_images, train_path_img, val_path_img)\n",
        "move_files(val_labels, train_path_label, val_path_label)\n",
        "\n",
        "print(\"Data split and files moved successfully!\")\n"
      ],
      "metadata": {
        "id": "zyFYYz7NN6Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content/drive/MyDrive/Yolov/LICENSE_DATA'"
      ],
      "metadata": {
        "id": "FaUYD6OWI8i4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "VUjGGWexg3QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8s.pt')\n",
        "results = model.train(data=os.path.join(ROOT_DIR, \"data.yaml\"), epochs=10, imgsz=640)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trxQkvkQK1f3",
        "outputId": "de0433b1-6ceb-4f15-e645-2129c9b16c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 245MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/Yolov/LICENSE_DATA/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 22.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11135987 parameters, 11135971 gradients, 28.6 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 95.5MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/labels/train.cache... 1440 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1440/1440 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/labels/val.cache... 360 images, 0 backgrounds, 0 corrupt: 100%|██████████| 360/360 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10      4.19G      1.358      3.046      1.168         16        640: 100%|██████████| 90/90 [05:41<00:00,  3.80s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:09<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.824      0.858      0.882       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      4.14G      1.304     0.9461      1.144         16        640: 100%|██████████| 90/90 [00:42<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360       0.02      0.858     0.0197     0.0114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      4.11G      1.349     0.9179      1.166         15        640: 100%|██████████| 90/90 [00:46<00:00,  1.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.245      0.758      0.237      0.141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      4.14G      1.289     0.8568       1.15         16        640: 100%|██████████| 90/90 [00:41<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.846      0.917      0.931       0.58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      4.13G      1.216     0.7786        1.1         16        640: 100%|██████████| 90/90 [00:42<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:06<00:00,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.963      0.958       0.98      0.674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      4.14G      1.135     0.6941      1.054         16        640: 100%|██████████| 90/90 [00:43<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:07<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.911      0.939      0.931      0.643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      4.14G       1.11     0.6506      1.037         16        640: 100%|██████████| 90/90 [00:42<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360       0.96      0.978      0.988      0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      4.14G      1.053     0.6185       1.02         15        640: 100%|██████████| 90/90 [00:43<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.983      0.989      0.991      0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      4.14G          1      0.556     0.9931         15        640: 100%|██████████| 90/90 [00:41<00:00,  2.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:05<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.977      0.989      0.991      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      4.14G     0.9453     0.5205     0.9833         15        640: 100%|██████████| 90/90 [00:43<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04<00:00,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.984      0.989      0.991      0.752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.228 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:08<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.984      0.989      0.991      0.752\n",
            "Speed: 0.5ms preprocess, 3.8ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USING TRAINED MODEL**"
      ],
      "metadata": {
        "id": "YkPgDHtZgeQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'best.pt' is saved at 'runs/train/exp1/weights/best.pt'\n",
        "trained_model = YOLO('/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/runs/detect/train2/weights/best.pt')\n"
      ],
      "metadata": {
        "id": "KpqamyYrZ_CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VALIDATING THE MODEL**"
      ],
      "metadata": {
        "id": "Uz7GWJWSgYLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "metrics = trained_model.val(data=os.path.join(ROOT_DIR, \"data.yaml\"), split=\"val\", visualize=True)\n",
        "# no arguments needed, dataset and settings remembered\n",
        "metrics.box.map  # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps  # a list contains map50-95 of each category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIvqRTPA8L6",
        "outputId": "3e865ce7-3cf1-454d-e6f0-ca7891d3f4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients, 28.4 GFLOPs\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 14.6MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/labels/val.cache... 360 images, 0 backgrounds, 0 corrupt: 100%|██████████| 360/360 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 23/23 [04:03<00:00, 10.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        360        360      0.904      0.867      0.929      0.585\n",
            "Speed: 1.6ms preprocess, 634.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0.58471])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'test' section in data.yaml defines test data path\n",
        "test_data_path = \"/content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test\""
      ],
      "metadata": {
        "id": "uIEQVaetyX-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PREDICTING THE TEST SET**"
      ],
      "metadata": {
        "id": "Gb1b-V61gMuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on test data and save results\n",
        "results = trained_model.predict(test_data_path, save_crop = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Cq4IR5zBBO",
        "outputId": "de2d61f8-fe47-4101-e158-3647f56f0345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1000.jpg: 448x640 3 license_plates, 739.3ms\n",
            "image 2/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1001.jpg: 640x384 1 license_plate, 411.0ms\n",
            "image 3/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1002.jpg: 640x480 2 license_plates, 973.4ms\n",
            "image 4/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1003.jpg: 384x640 1 license_plate, 956.5ms\n",
            "image 5/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1004.jpg: 640x384 1 license_plate, 1554.9ms\n",
            "image 6/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1005.jpg: 640x384 1 license_plate, 1395.2ms\n",
            "image 7/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1006.jpg: 640x480 1 license_plate, 2209.2ms\n",
            "image 8/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1007.jpg: 640x384 1 license_plate, 1067.4ms\n",
            "image 9/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1008.jpg: 384x640 1 license_plate, 495.0ms\n",
            "image 10/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1009.jpg: 384x640 1 license_plate, 390.0ms\n",
            "image 11/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1010.jpg: 640x384 (no detections), 387.0ms\n",
            "image 12/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1011.jpg: 640x384 1 license_plate, 433.6ms\n",
            "image 13/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1012.jpg: 480x640 1 license_plate, 491.0ms\n",
            "image 14/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1013.jpg: 640x480 1 license_plate, 506.7ms\n",
            "image 15/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1014.jpg: 480x640 1 license_plate, 499.1ms\n",
            "image 16/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1015.jpg: 480x640 1 license_plate, 514.5ms\n",
            "image 17/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1016.jpg: 480x640 1 license_plate, 503.9ms\n",
            "image 18/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1017.jpg: 384x640 2 license_plates, 408.3ms\n",
            "image 19/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1018.jpg: 480x640 2 license_plates, 498.2ms\n",
            "image 20/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1019.jpg: 384x640 1 license_plate, 419.1ms\n",
            "image 21/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1020.jpg: 640x480 1 license_plate, 521.8ms\n",
            "image 22/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1021.jpg: 640x384 1 license_plate, 421.9ms\n",
            "image 23/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1022.jpg: 384x640 1 license_plate, 387.3ms\n",
            "image 24/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1023.jpg: 384x640 1 license_plate, 384.8ms\n",
            "image 25/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1024.jpg: 384x640 1 license_plate, 411.3ms\n",
            "image 26/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1025.jpg: 640x480 1 license_plate, 517.7ms\n",
            "image 27/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1026.jpg: 640x480 1 license_plate, 585.1ms\n",
            "image 28/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1027.jpg: 384x640 1 license_plate, 636.2ms\n",
            "image 29/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1028.jpg: 640x480 1 license_plate, 1021.1ms\n",
            "image 30/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1029.jpg: 384x640 1 license_plate, 1529.2ms\n",
            "image 31/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1030.jpg: 384x640 1 license_plate, 1799.2ms\n",
            "image 32/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1031.jpg: 480x640 1 license_plate, 1928.2ms\n",
            "image 33/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1032.jpg: 640x480 2 license_plates, 1002.6ms\n",
            "image 34/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1033.jpg: 480x640 2 license_plates, 626.7ms\n",
            "image 35/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1034.jpg: 640x480 1 license_plate, 526.3ms\n",
            "image 36/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1035.jpg: 640x480 1 license_plate, 519.0ms\n",
            "image 37/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1036.jpg: 640x480 1 license_plate, 527.8ms\n",
            "image 38/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1037.jpg: 384x640 1 license_plate, 402.6ms\n",
            "image 39/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1038.jpg: 640x384 1 license_plate, 442.8ms\n",
            "image 40/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1039.jpg: 384x640 1 license_plate, 382.6ms\n",
            "image 41/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1040.jpg: 640x480 1 license_plate, 520.5ms\n",
            "image 42/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1041.jpg: 384x640 1 license_plate, 401.4ms\n",
            "image 43/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1042.jpg: 384x640 1 license_plate, 405.5ms\n",
            "image 44/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1043.jpg: 640x544 1 license_plate, 575.9ms\n",
            "image 45/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1044.jpg: 640x480 1 license_plate, 477.6ms\n",
            "image 46/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1045.jpg: 480x640 1 license_plate, 463.8ms\n",
            "image 47/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1046.jpg: 640x480 1 license_plate, 480.8ms\n",
            "image 48/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1047.jpg: 480x640 1 license_plate, 739.2ms\n",
            "image 49/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1048.jpg: 480x640 1 license_plate, 703.8ms\n",
            "image 50/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1049.jpg: 640x480 1 license_plate, 2096.1ms\n",
            "image 51/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1050.jpg: 512x640 2 license_plates, 1837.4ms\n",
            "image 52/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1051.jpg: 416x640 1 license_plate, 2388.2ms\n",
            "image 53/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1052.jpg: 384x640 3 license_plates, 1090.9ms\n",
            "image 54/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1053.jpg: 640x480 1 license_plate, 857.9ms\n",
            "image 55/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1054.jpg: 384x640 1 license_plate, 403.7ms\n",
            "image 56/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1055.jpg: 640x384 1 license_plate, 406.8ms\n",
            "image 57/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1056.jpg: 640x480 1 license_plate, 512.9ms\n",
            "image 58/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1057.jpg: 640x544 1 license_plate, 546.2ms\n",
            "image 59/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1058.jpg: 384x640 1 license_plate, 404.8ms\n",
            "image 60/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1059.jpg: 384x640 1 license_plate, 412.8ms\n",
            "image 61/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1060.jpg: 640x416 2 license_plates, 472.8ms\n",
            "image 62/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1061.jpg: 640x384 1 license_plate, 443.1ms\n",
            "image 63/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1062.jpg: 384x640 1 license_plate, 419.0ms\n",
            "image 64/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1063.jpg: 640x480 1 license_plate, 509.7ms\n",
            "image 65/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1064.jpg: 640x384 1 license_plate, 400.8ms\n",
            "image 66/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1065.jpg: 640x544 3 license_plates, 560.1ms\n",
            "image 67/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1066.jpg: 640x544 2 license_plates, 544.1ms\n",
            "image 68/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1067.jpg: 640x480 2 license_plates, 501.3ms\n",
            "image 69/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1068.jpg: 480x640 3 license_plates, 498.4ms\n",
            "image 70/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1069.jpg: 384x640 2 license_plates, 392.8ms\n",
            "image 71/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1070.jpg: 640x384 1 license_plate, 407.7ms\n",
            "image 72/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1071.jpg: 640x480 1 license_plate, 548.7ms\n",
            "image 73/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1072.jpg: 480x640 1 license_plate, 748.4ms\n",
            "image 74/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1073.jpg: 448x640 1 license_plate, 699.5ms\n",
            "image 75/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1074.jpg: 480x640 2 license_plates, 789.1ms\n",
            "image 76/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1075.jpg: 640x480 (no detections), 812.2ms\n",
            "image 77/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1076.jpg: 640x480 2 license_plates, 811.5ms\n",
            "image 78/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1077.jpg: 480x640 1 license_plate, 823.3ms\n",
            "image 79/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1078.jpg: 640x480 1 license_plate, 791.0ms\n",
            "image 80/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1079.jpg: 640x384 1 license_plate, 499.5ms\n",
            "image 81/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1080.jpg: 640x480 1 license_plate, 490.0ms\n",
            "image 82/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1081.jpg: 640x480 1 license_plate, 506.4ms\n",
            "image 83/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1082.jpg: 640x480 1 license_plate, 498.3ms\n",
            "image 84/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1083.jpg: 640x480 1 license_plate, 503.8ms\n",
            "image 85/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1084.jpg: 480x640 1 license_plate, 462.9ms\n",
            "image 86/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1085.jpg: 640x480 2 license_plates, 514.6ms\n",
            "image 87/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1086.jpg: 384x640 2 license_plates, 378.9ms\n",
            "image 88/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1087.jpg: 640x512 3 license_plates, 540.0ms\n",
            "image 89/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1088.jpg: 384x640 2 license_plates, 392.7ms\n",
            "image 90/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1089.jpg: 384x640 1 license_plate, 390.0ms\n",
            "image 91/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1090.jpg: 640x480 1 license_plate, 514.9ms\n",
            "image 92/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1091.jpg: 384x640 1 license_plate, 383.6ms\n",
            "image 93/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1092.jpg: 384x640 1 license_plate, 413.8ms\n",
            "image 94/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1093.jpg: 640x384 1 license_plate, 399.1ms\n",
            "image 95/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1094.jpg: 480x640 2 license_plates, 491.7ms\n",
            "image 96/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1095.jpg: 512x640 1 license_plate, 512.4ms\n",
            "image 97/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1096.jpg: 480x640 1 license_plate, 520.5ms\n",
            "image 98/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1098.jpg: 384x640 1 license_plate, 689.2ms\n",
            "image 99/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1099.jpg: 480x640 1 license_plate, 479.0ms\n",
            "image 100/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1100.jpg: 384x640 1 license_plate, 547.7ms\n",
            "image 101/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1101.jpg: 480x640 1 license_plate, 727.2ms\n",
            "image 102/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1102.jpg: 640x480 3 license_plates, 751.1ms\n",
            "image 103/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1103.jpg: 480x640 1 license_plate, 728.8ms\n",
            "image 104/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1104.jpg: 640x384 1 license_plate, 595.1ms\n",
            "image 105/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1105.jpg: 640x480 1 license_plate, 772.2ms\n",
            "image 106/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1106.jpg: 640x480 1 license_plate, 797.0ms\n",
            "image 107/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1107.jpg: 480x640 2 license_plates, 729.0ms\n",
            "image 108/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1108.jpg: 480x640 2 license_plates, 550.9ms\n",
            "image 109/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1109.jpg: 640x384 2 license_plates, 407.3ms\n",
            "image 110/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1110.jpg: 640x480 1 license_plate, 510.9ms\n",
            "image 111/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1111.jpg: 640x384 1 license_plate, 407.1ms\n",
            "image 112/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1112.jpg: 640x480 1 license_plate, 523.7ms\n",
            "image 113/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/1113.jpg: 384x640 2 license_plates, 409.7ms\n",
            "image 114/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/901.jpg: 640x480 2 license_plates, 519.5ms\n",
            "image 115/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/902.jpg: 384x640 1 license_plate, 398.5ms\n",
            "image 116/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/903.jpg: 640x480 1 license_plate, 506.5ms\n",
            "image 117/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/904.jpg: 384x640 2 license_plates, 388.7ms\n",
            "image 118/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/905.jpg: 640x480 1 license_plate, 511.1ms\n",
            "image 119/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/906.jpg: 384x640 1 license_plate, 388.3ms\n",
            "image 120/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/907.jpg: 640x480 1 license_plate, 503.1ms\n",
            "image 121/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/908.jpg: 384x640 1 license_plate, 387.0ms\n",
            "image 122/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/909.jpg: 640x480 1 license_plate, 487.1ms\n",
            "image 123/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/910.jpg: 384x640 2 license_plates, 412.3ms\n",
            "image 124/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/911.jpg: 640x480 2 license_plates, 491.4ms\n",
            "image 125/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/912.jpg: 384x640 2 license_plates, 398.1ms\n",
            "image 126/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/913.jpg: 480x640 1 license_plate, 488.0ms\n",
            "image 127/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/914.jpg: 384x640 1 license_plate, 404.8ms\n",
            "image 128/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/915.jpg: 384x640 3 license_plates, 387.6ms\n",
            "image 129/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/917.jpg: 480x640 2 license_plates, 709.9ms\n",
            "image 130/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/918.jpg: 480x640 1 license_plate, 759.0ms\n",
            "image 131/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/919.jpg: 384x640 2 license_plates, 618.4ms\n",
            "image 132/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/920.jpg: 384x640 1 license_plate, 631.0ms\n",
            "image 133/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/921.jpg: 480x640 4 license_plates, 806.2ms\n",
            "image 134/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/922.jpg: 640x640 1 license_plate, 1136.0ms\n",
            "image 135/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/923.jpg: 640x480 (no detections), 631.0ms\n",
            "image 136/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/924.jpg: 480x640 2 license_plates, 466.7ms\n",
            "image 137/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/925.jpg: 640x384 2 license_plates, 388.3ms\n",
            "image 138/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/926.jpg: 640x512 1 license_plate, 532.9ms\n",
            "image 139/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/927.jpg: 640x480 1 license_plate, 474.0ms\n",
            "image 140/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/928.jpg: 480x640 1 license_plate, 467.5ms\n",
            "image 141/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/929.jpg: 480x640 1 license_plate, 472.3ms\n",
            "image 142/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/930.jpg: 448x640 4 license_plates, 463.0ms\n",
            "image 143/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/931.jpg: 480x640 1 license_plate, 482.4ms\n",
            "image 144/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/932.jpg: 640x480 1 license_plate, 492.8ms\n",
            "image 145/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/933.jpg: 640x480 1 license_plate, 482.8ms\n",
            "image 146/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/934.jpg: 384x640 3 license_plates, 385.7ms\n",
            "image 147/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/935.jpg: 640x480 1 license_plate, 485.7ms\n",
            "image 148/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/936.jpg: 384x640 1 license_plate, 384.4ms\n",
            "image 149/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/937.jpg: 480x640 1 license_plate, 490.2ms\n",
            "image 150/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/938.jpg: 640x576 1 license_plate, 590.2ms\n",
            "image 151/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/939.jpg: 480x640 1 license_plate, 493.6ms\n",
            "image 152/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/940.jpg: 448x640 1 license_plate, 445.1ms\n",
            "image 153/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/941.jpg: 480x640 1 license_plate, 496.3ms\n",
            "image 154/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/942.jpg: 384x640 1 license_plate, 383.0ms\n",
            "image 155/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/943.jpg: 640x576 1 license_plate, 645.6ms\n",
            "image 156/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/944.jpg: 640x480 1 license_plate, 797.2ms\n",
            "image 157/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/945.jpg: 384x640 1 license_plate, 592.3ms\n",
            "image 158/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/946.jpg: 480x640 2 license_plates, 758.4ms\n",
            "image 159/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/947.jpg: 640x384 1 license_plate, 621.7ms\n",
            "image 160/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/948.jpg: 384x640 1 license_plate, 625.4ms\n",
            "image 161/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/949.jpg: 640x384 1 license_plate, 676.2ms\n",
            "image 162/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/950.jpg: 480x640 1 license_plate, 776.1ms\n",
            "image 163/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/951.jpg: 384x640 1 license_plate, 382.1ms\n",
            "image 164/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/952.jpg: 384x640 2 license_plates, 426.8ms\n",
            "image 165/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/953.jpg: 480x640 2 license_plates, 487.6ms\n",
            "image 166/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/954.jpg: 384x640 1 license_plate, 411.7ms\n",
            "image 167/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/955.jpg: 640x384 1 license_plate, 431.6ms\n",
            "image 168/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/956.jpg: 384x640 1 license_plate, 420.6ms\n",
            "image 169/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/957.jpg: 384x640 1 license_plate, 408.3ms\n",
            "image 170/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/958.jpg: 384x640 1 license_plate, 399.3ms\n",
            "image 171/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/959.jpg: 640x384 1 license_plate, 415.8ms\n",
            "image 172/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/960.jpg: 416x640 1 license_plate, 403.3ms\n",
            "image 173/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/961.jpg: 640x480 1 license_plate, 499.5ms\n",
            "image 174/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/962.jpg: 384x640 1 license_plate, 377.9ms\n",
            "image 175/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/963.jpg: 384x640 1 license_plate, 390.8ms\n",
            "image 176/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/964.jpg: 480x640 2 license_plates, 494.0ms\n",
            "image 177/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/965.jpg: 640x480 2 license_plates, 489.4ms\n",
            "image 178/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/966.jpg: 480x640 1 license_plate, 488.3ms\n",
            "image 179/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/967.jpg: 640x480 1 license_plate, 493.5ms\n",
            "image 180/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/968.jpg: 640x480 2 license_plates, 499.2ms\n",
            "image 181/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/969.jpg: 640x480 1 license_plate, 479.9ms\n",
            "image 182/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/970.jpg: 384x640 2 license_plates, 418.7ms\n",
            "image 183/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/971.jpg: 480x640 1 license_plate, 471.3ms\n",
            "image 184/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/972.jpg: 480x640 1 license_plate, 671.1ms\n",
            "image 185/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/973.jpg: 640x480 2 license_plates, 754.2ms\n",
            "image 186/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/974.jpg: 448x640 4 license_plates, 690.3ms\n",
            "image 187/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/975.jpg: 640x384 2 license_plates, 602.8ms\n",
            "image 188/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/976.jpg: 480x640 1 license_plate, 773.1ms\n",
            "image 189/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/977.jpg: 480x640 1 license_plate, 833.0ms\n",
            "image 190/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/978.jpg: 384x640 3 license_plates, 592.5ms\n",
            "image 191/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/979.jpg: 480x640 1 license_plate, 484.5ms\n",
            "image 192/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/981.jpg: 448x640 1 license_plate, 454.2ms\n",
            "image 193/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/982.jpg: 640x384 1 license_plate, 392.0ms\n",
            "image 194/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/983.jpg: 480x640 1 license_plate, 507.6ms\n",
            "image 195/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/984.jpg: 480x640 1 license_plate, 475.9ms\n",
            "image 196/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/985.jpg: 640x480 1 license_plate, 480.4ms\n",
            "image 197/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/986.jpg: 480x640 2 license_plates, 462.8ms\n",
            "image 198/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/987.jpg: 480x640 1 license_plate, 481.3ms\n",
            "image 199/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/988.jpg: 640x480 1 license_plate, 495.7ms\n",
            "image 200/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/989.jpg: 384x640 1 license_plate, 395.2ms\n",
            "image 201/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/990.jpg: 640x480 1 license_plate, 516.3ms\n",
            "image 202/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/991.jpg: 480x640 1 license_plate, 492.2ms\n",
            "image 203/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/992.jpg: 640x480 1 license_plate, 488.4ms\n",
            "image 204/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/993.jpg: 640x384 1 license_plate, 413.8ms\n",
            "image 205/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/994.jpg: 640x480 1 license_plate, 499.7ms\n",
            "image 206/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/995.jpg: 480x640 (no detections), 481.9ms\n",
            "image 207/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/996.jpg: 480x640 1 license_plate, 478.5ms\n",
            "image 208/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/997.jpg: 640x480 1 license_plate, 525.2ms\n",
            "image 209/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/998.jpg: 640x480 1 license_plate, 481.1ms\n",
            "image 210/210 /content/drive/MyDrive/Yolov/LICENSE_DATA/Data/test/test/999.jpg: 384x640 1 license_plate, 405.4ms\n",
            "Speed: 3.8ms preprocess, 592.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LICENSE PLATE RECOGNITION**"
      ],
      "metadata": {
        "id": "IVX_Hu-wgCGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to folder containing cropped license plates\n",
        "plate_dir = \"/content/runs/detect/predict/crops/license_plate\"\n",
        "\n",
        "# Define output folder to save recognized text\n",
        "output_dir = \"/content/drive/MyDrive/Yolov/LICENSE_DATA/plate_recognition\"\n",
        "\n",
        "# Initialize EasyOCR reader (adjust language code if needed)\n",
        "reader = Reader(['ar', 'en'])  # Arabic and English languages\n",
        "\n",
        "# Loop through each image in the directory\n",
        "for filename in os.listdir(plate_dir):\n",
        "  if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "    # Construct image path\n",
        "    img_path = os.path.join(plate_dir, filename)\n",
        "\n",
        "    # Perform text recognition\n",
        "    result = reader.readtext(img_path, detail=0)\n",
        "\n",
        "    # Extract recognized text (handle empty results)\n",
        "    if result:\n",
        "      recognized_text = \" \".join(result)\n",
        "    else:\n",
        "      recognized_text = \"N/A\"  # Set default text if no recognition\n",
        "\n",
        "    # Construct output file path (remove extension and add .txt)\n",
        "    output_filename = os.path.splitext(filename)[0] + \".txt\"  # Get filename without extension\n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "    # Save recognized text to file\n",
        "    with open(output_path, \"w\") as f:\n",
        "      f.write(recognized_text)\n",
        "\n",
        "    print(f\"Text recognized for {filename} and saved to {output_filename}\")\n",
        "\n",
        "print(\"Text recognition completed for all images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsi3ODOu8557",
        "outputId": "819619c4-4ed8-41b8-df21-560fe864176a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text recognized for 1016.jpg and saved to 1016.txt\n",
            "Text recognized for 1047.jpg and saved to 1047.txt\n",
            "Text recognized for 1091.jpg and saved to 1091.txt\n",
            "Text recognized for 1031.jpg and saved to 1031.txt\n",
            "Text recognized for 10683.jpg and saved to 10683.txt\n",
            "Text recognized for 1085.jpg and saved to 1085.txt\n",
            "Text recognized for 1094.jpg and saved to 1094.txt\n",
            "Text recognized for 1071.jpg and saved to 1071.txt\n",
            "Text recognized for 919.jpg and saved to 919.txt\n",
            "Text recognized for 9212.jpg and saved to 9212.txt\n",
            "Text recognized for 1049.jpg and saved to 1049.txt\n",
            "Text recognized for 10942.jpg and saved to 10942.txt\n",
            "Text recognized for 1074.jpg and saved to 1074.txt\n",
            "Text recognized for 931.jpg and saved to 931.txt\n",
            "Text recognized for 10332.jpg and saved to 10332.txt\n",
            "Text recognized for 930.jpg and saved to 930.txt\n",
            "Text recognized for 934.jpg and saved to 934.txt\n",
            "Text recognized for 9302.jpg and saved to 9302.txt\n",
            "Text recognized for 10682.jpg and saved to 10682.txt\n",
            "Text recognized for 1040.jpg and saved to 1040.txt\n",
            "Text recognized for 945.jpg and saved to 945.txt\n",
            "Text recognized for 943.jpg and saved to 943.txt\n",
            "Text recognized for 1086.jpg and saved to 1086.txt\n",
            "Text recognized for 10882.jpg and saved to 10882.txt\n",
            "Text recognized for 992.jpg and saved to 992.txt\n",
            "Text recognized for 1017.jpg and saved to 1017.txt\n",
            "Text recognized for 9744.jpg and saved to 9744.txt\n",
            "Text recognized for 1000.jpg and saved to 1000.txt\n",
            "Text recognized for 9782.jpg and saved to 9782.txt\n",
            "Text recognized for 9342.jpg and saved to 9342.txt\n",
            "Text recognized for 928.jpg and saved to 928.txt\n",
            "Text recognized for 1007.jpg and saved to 1007.txt\n",
            "Text recognized for 918.jpg and saved to 918.txt\n",
            "Text recognized for 947.jpg and saved to 947.txt\n",
            "Text recognized for 922.jpg and saved to 922.txt\n",
            "Text recognized for 954.jpg and saved to 954.txt\n",
            "Text recognized for 10692.jpg and saved to 10692.txt\n",
            "Text recognized for 1087.jpg and saved to 1087.txt\n",
            "Text recognized for 1044.jpg and saved to 1044.txt\n",
            "Text recognized for 10002.jpg and saved to 10002.txt\n",
            "Text recognized for 1081.jpg and saved to 1081.txt\n",
            "Text recognized for 9304.jpg and saved to 9304.txt\n",
            "Text recognized for 1064.jpg and saved to 1064.txt\n",
            "Text recognized for 1022.jpg and saved to 1022.txt\n",
            "Text recognized for 9172.jpg and saved to 9172.txt\n",
            "Text recognized for 1078.jpg and saved to 1078.txt\n",
            "Text recognized for 966.jpg and saved to 966.txt\n",
            "Text recognized for 924.jpg and saved to 924.txt\n",
            "Text recognized for 984.jpg and saved to 984.txt\n",
            "Text recognized for 9153.jpg and saved to 9153.txt\n",
            "Text recognized for 951.jpg and saved to 951.txt\n",
            "Text recognized for 1032.jpg and saved to 1032.txt\n",
            "Text recognized for 985.jpg and saved to 985.txt\n",
            "Text recognized for 1036.jpg and saved to 1036.txt\n",
            "Text recognized for 915.jpg and saved to 915.txt\n",
            "Text recognized for 1066.jpg and saved to 1066.txt\n",
            "Text recognized for 914.jpg and saved to 914.txt\n",
            "Text recognized for 1103.jpg and saved to 1103.txt\n",
            "Text recognized for 1108.jpg and saved to 1108.txt\n",
            "Text recognized for 11082.jpg and saved to 11082.txt\n",
            "Text recognized for 999.jpg and saved to 999.txt\n",
            "Text recognized for 1090.jpg and saved to 1090.txt\n",
            "Text recognized for 989.jpg and saved to 989.txt\n",
            "Text recognized for 1077.jpg and saved to 1077.txt\n",
            "Text recognized for 953.jpg and saved to 953.txt\n",
            "Text recognized for 906.jpg and saved to 906.txt\n",
            "Text recognized for 993.jpg and saved to 993.txt\n",
            "Text recognized for 1060.jpg and saved to 1060.txt\n",
            "Text recognized for 9012.jpg and saved to 9012.txt\n",
            "Text recognized for 1025.jpg and saved to 1025.txt\n",
            "Text recognized for 10742.jpg and saved to 10742.txt\n",
            "Text recognized for 1057.jpg and saved to 1057.txt\n",
            "Text recognized for 912.jpg and saved to 912.txt\n",
            "Text recognized for 10672.jpg and saved to 10672.txt\n",
            "Text recognized for 982.jpg and saved to 982.txt\n",
            "Text recognized for 903.jpg and saved to 903.txt\n",
            "Text recognized for 1013.jpg and saved to 1013.txt\n",
            "Text recognized for 1070.jpg and saved to 1070.txt\n",
            "Text recognized for 1001.jpg and saved to 1001.txt\n",
            "Text recognized for 11092.jpg and saved to 11092.txt\n",
            "Text recognized for 10662.jpg and saved to 10662.txt\n",
            "Text recognized for 1056.jpg and saved to 1056.txt\n",
            "Text recognized for 1080.jpg and saved to 1080.txt\n",
            "Text recognized for 1023.jpg and saved to 1023.txt\n",
            "Text recognized for 938.jpg and saved to 938.txt\n",
            "Text recognized for 965.jpg and saved to 965.txt\n",
            "Text recognized for 9214.jpg and saved to 9214.txt\n",
            "Text recognized for 942.jpg and saved to 942.txt\n",
            "Text recognized for 1068.jpg and saved to 1068.txt\n",
            "Text recognized for 1045.jpg and saved to 1045.txt\n",
            "Text recognized for 9702.jpg and saved to 9702.txt\n",
            "Text recognized for 1058.jpg and saved to 1058.txt\n",
            "Text recognized for 960.jpg and saved to 960.txt\n",
            "Text recognized for 927.jpg and saved to 927.txt\n",
            "Text recognized for 9152.jpg and saved to 9152.txt\n",
            "Text recognized for 920.jpg and saved to 920.txt\n",
            "Text recognized for 957.jpg and saved to 957.txt\n",
            "Text recognized for 1008.jpg and saved to 1008.txt\n",
            "Text recognized for 1069.jpg and saved to 1069.txt\n",
            "Text recognized for 977.jpg and saved to 977.txt\n",
            "Text recognized for 1004.jpg and saved to 1004.txt\n",
            "Text recognized for 9642.jpg and saved to 9642.txt\n",
            "Text recognized for 1011.jpg and saved to 1011.txt\n",
            "Text recognized for 9522.jpg and saved to 9522.txt\n",
            "Text recognized for 946.jpg and saved to 946.txt\n",
            "Text recognized for 972.jpg and saved to 972.txt\n",
            "Text recognized for 1065.jpg and saved to 1065.txt\n",
            "Text recognized for 987.jpg and saved to 987.txt\n",
            "Text recognized for 967.jpg and saved to 967.txt\n",
            "Text recognized for 996.jpg and saved to 996.txt\n",
            "Text recognized for 1109.jpg and saved to 1109.txt\n",
            "Text recognized for 10602.jpg and saved to 10602.txt\n",
            "Text recognized for 1030.jpg and saved to 1030.txt\n",
            "Text recognized for 10873.jpg and saved to 10873.txt\n",
            "Text recognized for 1020.jpg and saved to 1020.txt\n",
            "Text recognized for 1046.jpg and saved to 1046.txt\n",
            "Text recognized for 9732.jpg and saved to 9732.txt\n",
            "Text recognized for 10523.jpg and saved to 10523.txt\n",
            "Text recognized for 9112.jpg and saved to 9112.txt\n",
            "Text recognized for 10872.jpg and saved to 10872.txt\n",
            "Text recognized for 1061.jpg and saved to 1061.txt\n",
            "Text recognized for 907.jpg and saved to 907.txt\n",
            "Text recognized for 964.jpg and saved to 964.txt\n",
            "Text recognized for 1067.jpg and saved to 1067.txt\n",
            "Text recognized for 1105.jpg and saved to 1105.txt\n",
            "Text recognized for 929.jpg and saved to 929.txt\n",
            "Text recognized for 941.jpg and saved to 941.txt\n",
            "Text recognized for 11023.jpg and saved to 11023.txt\n",
            "Text recognized for 1029.jpg and saved to 1029.txt\n",
            "Text recognized for 925.jpg and saved to 925.txt\n",
            "Text recognized for 917.jpg and saved to 917.txt\n",
            "Text recognized for 1009.jpg and saved to 1009.txt\n",
            "Text recognized for 1104.jpg and saved to 1104.txt\n",
            "Text recognized for 955.jpg and saved to 955.txt\n",
            "Text recognized for 11072.jpg and saved to 11072.txt\n",
            "Text recognized for 963.jpg and saved to 963.txt\n",
            "Text recognized for 1015.jpg and saved to 1015.txt\n",
            "Text recognized for 10182.jpg and saved to 10182.txt\n",
            "Text recognized for 1027.jpg and saved to 1027.txt\n",
            "Text recognized for 1003.jpg and saved to 1003.txt\n",
            "Text recognized for 9532.jpg and saved to 9532.txt\n",
            "Text recognized for 1034.jpg and saved to 1034.txt\n",
            "Text recognized for 1019.jpg and saved to 1019.txt\n",
            "Text recognized for 1035.jpg and saved to 1035.txt\n",
            "Text recognized for 9783.jpg and saved to 9783.txt\n",
            "Text recognized for 11132.jpg and saved to 11132.txt\n",
            "Text recognized for 1082.jpg and saved to 1082.txt\n",
            "Text recognized for 937.jpg and saved to 937.txt\n",
            "Text recognized for 1050.jpg and saved to 1050.txt\n",
            "Text recognized for 1076.jpg and saved to 1076.txt\n",
            "Text recognized for 1002.jpg and saved to 1002.txt\n",
            "Text recognized for 905.jpg and saved to 905.txt\n",
            "Text recognized for 9213.jpg and saved to 9213.txt\n",
            "Text recognized for 908.jpg and saved to 908.txt\n",
            "Text recognized for 1102.jpg and saved to 1102.txt\n",
            "Text recognized for 10322.jpg and saved to 10322.txt\n",
            "Text recognized for 944.jpg and saved to 944.txt\n",
            "Text recognized for 959.jpg and saved to 959.txt\n",
            "Text recognized for 952.jpg and saved to 952.txt\n",
            "Text recognized for 1101.jpg and saved to 1101.txt\n",
            "Text recognized for 10852.jpg and saved to 10852.txt\n",
            "Text recognized for 974.jpg and saved to 974.txt\n",
            "Text recognized for 1055.jpg and saved to 1055.txt\n",
            "Text recognized for 1033.jpg and saved to 1033.txt\n",
            "Text recognized for 1111.jpg and saved to 1111.txt\n",
            "Text recognized for 991.jpg and saved to 991.txt\n",
            "Text recognized for 1014.jpg and saved to 1014.txt\n",
            "Text recognized for 9862.jpg and saved to 9862.txt\n",
            "Text recognized for 9752.jpg and saved to 9752.txt\n",
            "Text recognized for 9462.jpg and saved to 9462.txt\n",
            "Text recognized for 10862.jpg and saved to 10862.txt\n",
            "Text recognized for 9252.jpg and saved to 9252.txt\n",
            "Text recognized for 1053.jpg and saved to 1053.txt\n",
            "Text recognized for 10762.jpg and saved to 10762.txt\n",
            "Text recognized for 969.jpg and saved to 969.txt\n",
            "Text recognized for 936.jpg and saved to 936.txt\n",
            "Text recognized for 978.jpg and saved to 978.txt\n",
            "Text recognized for 958.jpg and saved to 958.txt\n",
            "Text recognized for 9303.jpg and saved to 9303.txt\n",
            "Text recognized for 1072.jpg and saved to 1072.txt\n",
            "Text recognized for 1088.jpg and saved to 1088.txt\n",
            "Text recognized for 10022.jpg and saved to 10022.txt\n",
            "Text recognized for 913.jpg and saved to 913.txt\n",
            "Text recognized for 1084.jpg and saved to 1084.txt\n",
            "Text recognized for 9652.jpg and saved to 9652.txt\n",
            "Text recognized for 1043.jpg and saved to 1043.txt\n",
            "Text recognized for 1092.jpg and saved to 1092.txt\n",
            "Text recognized for 9343.jpg and saved to 9343.txt\n",
            "Text recognized for 1026.jpg and saved to 1026.txt\n",
            "Text recognized for 1063.jpg and saved to 1063.txt\n",
            "Text recognized for 1024.jpg and saved to 1024.txt\n",
            "Text recognized for 1112.jpg and saved to 1112.txt\n",
            "Text recognized for 1095.jpg and saved to 1095.txt\n",
            "Text recognized for 9122.jpg and saved to 9122.txt\n",
            "Text recognized for 10172.jpg and saved to 10172.txt\n",
            "Text recognized for 997.jpg and saved to 997.txt\n",
            "Text recognized for 11022.jpg and saved to 11022.txt\n",
            "Text recognized for 1089.jpg and saved to 1089.txt\n",
            "Text recognized for 994.jpg and saved to 994.txt\n",
            "Text recognized for 10522.jpg and saved to 10522.txt\n",
            "Text recognized for 983.jpg and saved to 983.txt\n",
            "Text recognized for 968.jpg and saved to 968.txt\n",
            "Text recognized for 1054.jpg and saved to 1054.txt\n",
            "Text recognized for 1021.jpg and saved to 1021.txt\n",
            "Text recognized for 949.jpg and saved to 949.txt\n",
            "Text recognized for 921.jpg and saved to 921.txt\n",
            "Text recognized for 1012.jpg and saved to 1012.txt\n",
            "Text recognized for 1048.jpg and saved to 1048.txt\n",
            "Text recognized for 1073.jpg and saved to 1073.txt\n",
            "Text recognized for 1041.jpg and saved to 1041.txt\n",
            "Text recognized for 950.jpg and saved to 950.txt\n",
            "Text recognized for 10653.jpg and saved to 10653.txt\n",
            "Text recognized for 10003.jpg and saved to 10003.txt\n",
            "Text recognized for 1059.jpg and saved to 1059.txt\n",
            "Text recognized for 911.jpg and saved to 911.txt\n",
            "Text recognized for 971.jpg and saved to 971.txt\n",
            "Text recognized for 902.jpg and saved to 902.txt\n",
            "Text recognized for 909.jpg and saved to 909.txt\n",
            "Text recognized for 904.jpg and saved to 904.txt\n",
            "Text recognized for 10502.jpg and saved to 10502.txt\n",
            "Text recognized for 926.jpg and saved to 926.txt\n",
            "Text recognized for 1006.jpg and saved to 1006.txt\n",
            "Text recognized for 1062.jpg and saved to 1062.txt\n",
            "Text recognized for 910.jpg and saved to 910.txt\n",
            "Text recognized for 9743.jpg and saved to 9743.txt\n",
            "Text recognized for 939.jpg and saved to 939.txt\n",
            "Text recognized for 973.jpg and saved to 973.txt\n",
            "Text recognized for 1079.jpg and saved to 1079.txt\n",
            "Text recognized for 1098.jpg and saved to 1098.txt\n",
            "Text recognized for 935.jpg and saved to 935.txt\n",
            "Text recognized for 948.jpg and saved to 948.txt\n",
            "Text recognized for 1110.jpg and saved to 1110.txt\n",
            "Text recognized for 1038.jpg and saved to 1038.txt\n",
            "Text recognized for 932.jpg and saved to 932.txt\n",
            "Text recognized for 988.jpg and saved to 988.txt\n",
            "Text recognized for 9102.jpg and saved to 9102.txt\n",
            "Text recognized for 1051.jpg and saved to 1051.txt\n",
            "Text recognized for 1099.jpg and saved to 1099.txt\n",
            "Text recognized for 979.jpg and saved to 979.txt\n",
            "Text recognized for 1037.jpg and saved to 1037.txt\n",
            "Text recognized for 9192.jpg and saved to 9192.txt\n",
            "Text recognized for 956.jpg and saved to 956.txt\n",
            "Text recognized for 1052.jpg and saved to 1052.txt\n",
            "Text recognized for 976.jpg and saved to 976.txt\n",
            "Text recognized for 1018.jpg and saved to 1018.txt\n",
            "Text recognized for 962.jpg and saved to 962.txt\n",
            "Text recognized for 1042.jpg and saved to 1042.txt\n",
            "Text recognized for 1100.jpg and saved to 1100.txt\n",
            "Text recognized for 975.jpg and saved to 975.txt\n",
            "Text recognized for 1113.jpg and saved to 1113.txt\n",
            "Text recognized for 998.jpg and saved to 998.txt\n",
            "Text recognized for 1096.jpg and saved to 1096.txt\n",
            "Text recognized for 1005.jpg and saved to 1005.txt\n",
            "Text recognized for 1083.jpg and saved to 1083.txt\n",
            "Text recognized for 1107.jpg and saved to 1107.txt\n",
            "Text recognized for 9742.jpg and saved to 9742.txt\n",
            "Text recognized for 1039.jpg and saved to 1039.txt\n",
            "Text recognized for 961.jpg and saved to 961.txt\n",
            "Text recognized for 901.jpg and saved to 901.txt\n",
            "Text recognized for 981.jpg and saved to 981.txt\n",
            "Text recognized for 10652.jpg and saved to 10652.txt\n",
            "Text recognized for 986.jpg and saved to 986.txt\n",
            "Text recognized for 9242.jpg and saved to 9242.txt\n",
            "Text recognized for 1093.jpg and saved to 1093.txt\n",
            "Text recognized for 990.jpg and saved to 990.txt\n",
            "Text recognized for 1106.jpg and saved to 1106.txt\n",
            "Text recognized for 970.jpg and saved to 970.txt\n",
            "Text recognized for 9042.jpg and saved to 9042.txt\n",
            "Text recognized for 1028.jpg and saved to 1028.txt\n",
            "Text recognized for 9682.jpg and saved to 9682.txt\n",
            "Text recognized for 933.jpg and saved to 933.txt\n",
            "Text recognized for 940.jpg and saved to 940.txt\n",
            "Text recognition completed for all images.\n"
          ]
        }
      ]
    }
  ]
}